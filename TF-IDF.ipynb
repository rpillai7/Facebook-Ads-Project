{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d1fca5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1091)>\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - '/Users/jpuray/nltk_data'\n    - '/Users/jpuray/venv/nltk_data'\n    - '/Users/jpuray/venv/share/nltk_data'\n    - '/Users/jpuray/venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - '/Users/jpuray/nltk_data'\n    - '/Users/jpuray/venv/nltk_data'\n    - '/Users/jpuray/venv/share/nltk_data'\n    - '/Users/jpuray/venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_n/2lzdwcvx2n9087rmk11qlfdw0000gn/T/ipykernel_16581/2238250036.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stopwords'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - '/Users/jpuray/nltk_data'\n    - '/Users/jpuray/venv/nltk_data'\n    - '/Users/jpuray/venv/share/nltk_data'\n    - '/Users/jpuray/venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import random\n",
    "import sklearn\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "08575f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a760f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads in file\n",
    "\n",
    "f = open(\"Ads5000\", \"rb\")\n",
    "ads = pickle.load(f)\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "900b3596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impressions</th>\n",
       "      <th>demographic_distribution</th>\n",
       "      <th>ad_creation_time</th>\n",
       "      <th>ad_delivery_start_time</th>\n",
       "      <th>delivery_by_region</th>\n",
       "      <th>estimated_audience_size</th>\n",
       "      <th>page_name</th>\n",
       "      <th>publisher_platforms</th>\n",
       "      <th>spend</th>\n",
       "      <th>id</th>\n",
       "      <th>ad_creative_link_description</th>\n",
       "      <th>ad_delivery_stop_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'lower_bound': '1000', 'upper_bound': '1999'}</td>\n",
       "      <td>[{'percentage': '0.004557', 'age': '18-24', 'g...</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>[{'percentage': '0.016578', 'region': 'Alabama...</td>\n",
       "      <td>{'lower_bound': '1000001'}</td>\n",
       "      <td>MomsRising.org</td>\n",
       "      <td>[facebook, instagram]</td>\n",
       "      <td>{'lower_bound': '0', 'upper_bound': '99'}</td>\n",
       "      <td>510093387113722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'lower_bound': '2000', 'upper_bound': '2999'}</td>\n",
       "      <td>[{'percentage': '0.000519', 'age': '25-34', 'g...</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>[{'percentage': '0.026604', 'region': 'Alabama...</td>\n",
       "      <td>{'lower_bound': '1000001'}</td>\n",
       "      <td>CPAC 2022</td>\n",
       "      <td>[facebook]</td>\n",
       "      <td>{'lower_bound': '0', 'upper_bound': '99'}</td>\n",
       "      <td>1010286123213947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'lower_bound': '0', 'upper_bound': '999'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'lower_bound': '10001', 'upper_bound': '50000'}</td>\n",
       "      <td>David Livingston Scott County Magistrate- 7th ...</td>\n",
       "      <td>[facebook]</td>\n",
       "      <td>{'lower_bound': '0', 'upper_bound': '99'}</td>\n",
       "      <td>726465978738772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'lower_bound': '0', 'upper_bound': '999'}</td>\n",
       "      <td>[{'percentage': '0.003436', 'age': '18-24', 'g...</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>[{'percentage': '1', 'region': 'Florida'}]</td>\n",
       "      <td>{'lower_bound': '1000001'}</td>\n",
       "      <td>Miami's Community Newspapers</td>\n",
       "      <td>[facebook, instagram]</td>\n",
       "      <td>{'lower_bound': '0', 'upper_bound': '99'}</td>\n",
       "      <td>1182151668859503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'lower_bound': '0', 'upper_bound': '999'}</td>\n",
       "      <td>[{'percentage': '0.021875', 'age': '25-34', 'g...</td>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>[{'percentage': '0.025316', 'region': 'Alabama...</td>\n",
       "      <td>{'lower_bound': '1000001'}</td>\n",
       "      <td>Pew Research Center</td>\n",
       "      <td>[facebook, instagram]</td>\n",
       "      <td>{'lower_bound': '0', 'upper_bound': '99'}</td>\n",
       "      <td>466037478231880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      impressions  \\\n",
       "0  {'lower_bound': '1000', 'upper_bound': '1999'}   \n",
       "1  {'lower_bound': '2000', 'upper_bound': '2999'}   \n",
       "2      {'lower_bound': '0', 'upper_bound': '999'}   \n",
       "3      {'lower_bound': '0', 'upper_bound': '999'}   \n",
       "4      {'lower_bound': '0', 'upper_bound': '999'}   \n",
       "\n",
       "                            demographic_distribution ad_creation_time  \\\n",
       "0  [{'percentage': '0.004557', 'age': '18-24', 'g...       2022-01-25   \n",
       "1  [{'percentage': '0.000519', 'age': '25-34', 'g...       2022-01-25   \n",
       "2                                                NaN       2022-01-25   \n",
       "3  [{'percentage': '0.003436', 'age': '18-24', 'g...       2022-01-25   \n",
       "4  [{'percentage': '0.021875', 'age': '25-34', 'g...       2022-01-21   \n",
       "\n",
       "  ad_delivery_start_time                                 delivery_by_region  \\\n",
       "0             2022-01-25  [{'percentage': '0.016578', 'region': 'Alabama...   \n",
       "1             2022-01-25  [{'percentage': '0.026604', 'region': 'Alabama...   \n",
       "2             2022-01-25                                                NaN   \n",
       "3             2022-01-25         [{'percentage': '1', 'region': 'Florida'}]   \n",
       "4             2022-01-25  [{'percentage': '0.025316', 'region': 'Alabama...   \n",
       "\n",
       "                            estimated_audience_size  \\\n",
       "0                        {'lower_bound': '1000001'}   \n",
       "1                        {'lower_bound': '1000001'}   \n",
       "2  {'lower_bound': '10001', 'upper_bound': '50000'}   \n",
       "3                        {'lower_bound': '1000001'}   \n",
       "4                        {'lower_bound': '1000001'}   \n",
       "\n",
       "                                           page_name    publisher_platforms  \\\n",
       "0                                     MomsRising.org  [facebook, instagram]   \n",
       "1                                          CPAC 2022             [facebook]   \n",
       "2  David Livingston Scott County Magistrate- 7th ...             [facebook]   \n",
       "3                       Miami's Community Newspapers  [facebook, instagram]   \n",
       "4                                Pew Research Center  [facebook, instagram]   \n",
       "\n",
       "                                       spend                id  \\\n",
       "0  {'lower_bound': '0', 'upper_bound': '99'}   510093387113722   \n",
       "1  {'lower_bound': '0', 'upper_bound': '99'}  1010286123213947   \n",
       "2  {'lower_bound': '0', 'upper_bound': '99'}   726465978738772   \n",
       "3  {'lower_bound': '0', 'upper_bound': '99'}  1182151668859503   \n",
       "4  {'lower_bound': '0', 'upper_bound': '99'}   466037478231880   \n",
       "\n",
       "  ad_creative_link_description ad_delivery_stop_time  \n",
       "0                          NaN                   NaN  \n",
       "1                          NaN                   NaN  \n",
       "2                          NaN                   NaN  \n",
       "3                          NaN                   NaN  \n",
       "4                          NaN                   NaN  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(ads)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f8e83dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops all ads with no description and turns it back into json \n",
    "\n",
    "df_with_only_descriptions = df.dropna()\n",
    "df_json = df_with_only_descriptions.to_json(orient='records')\n",
    "dataset = json.loads(df_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5b54150d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4779"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removes capitallization / punctuations\n",
    "\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in dataset:\n",
    "    r = ''.join([c for c in d['ad_creative_link_description'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1\n",
    "len(wordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "468dacd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stores an array of tuples with the number of times \n",
    " # each word appears across all the ads \n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c0697f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4779"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = [x[1] for x in counts]\n",
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1b511828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document frequency \n",
    "\n",
    "df = defaultdict(int)\n",
    "for d in dataset:\n",
    "    r = ''.join([c for c in d['ad_creative_link_description'].lower() if not c in punctuation])\n",
    "    for w in set(r.split()):\n",
    "        df[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2b0badc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# term frequency & TF - IDF\n",
    "tf = defaultdict(int)\n",
    "for d in dataset:\n",
    "    r = ''.join([c for c in d['ad_creative_link_description'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        # Note = rather than +=, different versions of tf could be used instead\n",
    "        tf[w] = 1\n",
    "    \n",
    "tfidf = dict(zip(words,[tf[w] * math.log2(len(dataset) / df[w]) for w in words]))\n",
    "tfidfQuery = [tf[w] * math.log2(len(dataset) / df[w]) for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8b28840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the highest tf-idf words in our example review\n",
    "\n",
    "maxTf = [(tf[w],w) for w in words]\n",
    "maxTf.sort(reverse=True)\n",
    "maxTfIdf = [(tfidf[w],w) for w in words]\n",
    "maxTfIdf.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "92cee66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10.615629636968098, 'ðŸ˜˜'),\n",
       " (10.615629636968098, 'ðŸ’‰'),\n",
       " (10.615629636968098, 'âœ”'),\n",
       " (10.615629636968098, 'âœ…no'),\n",
       " (10.615629636968098, 'âœ…january'),\n",
       " (10.615629636968098, 'âœ…free'),\n",
       " (10.615629636968098, 'âœ…food'),\n",
       " (10.615629636968098, 'â†’'),\n",
       " (10.615629636968098, 'â„–21â€“22â€“17'),\n",
       " (10.615629636968098, 'â€¦on')]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxTfIdf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cda14123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9151899188270054, 'to'),\n",
       " (1.0046048396607452, 'the'),\n",
       " (1.6184501560304763, 'and'),\n",
       " (1.6269449501959317, 'in'),\n",
       " (1.8674367873786373, 'a'),\n",
       " (2.1197746100809267, 'for'),\n",
       " (2.1521052636969173, 'of'),\n",
       " (2.26690148273702, 'now'),\n",
       " (2.391627962769993, 'covid19')]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxTfIdf[:-10:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc60158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
